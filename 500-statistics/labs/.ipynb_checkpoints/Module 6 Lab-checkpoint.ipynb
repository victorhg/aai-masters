{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6 Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import pandas as pd # for data science\n",
    "import numpy as np  # linear algebra library\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "import seaborn as sns # additional plotting library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Our DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin this lab, we are going to formulate a randomized dataset with *n*=100 observations. Let's suppose we have a class of 100 students who have taken three exams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_df(x, y, state): \n",
    "    np.random.seed(state) # set seed for reproducibility\n",
    "    # assign variable to a dataframe through the number 100\n",
    "    val = pd.DataFrame(np.random.randint(x, y, size=100))\n",
    "    val = val.round(decimals=0).astype(int) # no decimals, integers\n",
    "    return val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = rand_df(0, 100, 42) # exam 1\n",
    "df2 = rand_df(0, 100, 23) # exam 2\n",
    "df3 = rand_df(0, 100, 80) # exam 3\n",
    "df4 = rand_df(0, 20, 36) # study hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df1, df2, df3, df4]\n",
    "df5 = pd.concat(dfs, join='outer', axis=1)\n",
    "df5.columns = ['Exam 1', 'Exam 2', 'Exam 3', 'Study_Hours']\n",
    "df5['Final_Grade'] = df5[['Exam 1', 'Exam 2', 'Exam 3']].mean(axis=1)\n",
    "# no decimals, integers\n",
    "df5['Final_Grade'] = df5['Final_Grade'].round(decimals=0).astype(int) \n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df5['Exam 1'] \n",
    "y = df5['Final_Grade']\n",
    "plt.title('Final Grade vs. Exam 1')\n",
    "plt.xlabel('Exam 1')       \n",
    "plt.ylabel('Final Grade')           \n",
    "\n",
    "# create best-fit line based on slope-intercept form\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.scatter(x, y) \n",
    "plt.plot(x, m*x+b, color = 'red')\n",
    "\n",
    "# correlation coefficient \n",
    "corr = round(np.corrcoef(x, y)[0,1],2)\n",
    "plt.title('Final Grade vs. Exam 1;' ' $\\mathit{r}$ = ' + \"{:.2f}\".format(corr))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df5['Exam 2'] \n",
    "y = df5['Final_Grade']\n",
    "plt.title('Exam 2 vs. Final Grade')\n",
    "plt.xlabel('Exam 2')       \n",
    "plt.ylabel('Final Grade')           \n",
    "\n",
    "# create best-fit line based on slope-intercept form\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.scatter(x, y) \n",
    "plt.plot(x, m*x+b, color = 'red')\n",
    "corr = round(np.corrcoef(x, y)[0,1],2)\n",
    "plt.title('Exam 2 vs. Final Grade;' ' $\\mathit{r}$ = ' + \"{:.2f}\".format(corr))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df5['Exam 3'] \n",
    "y = df5['Final_Grade']\n",
    "plt.title('Exam 3 vs. Final Grade')\n",
    "plt.xlabel('Exam 3')       \n",
    "plt.ylabel('Final Grade')           \n",
    "\n",
    "# create best-fit line based on slope-intercept form\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.scatter(x, y) \n",
    "plt.plot(x, m*x+b, color = 'red')\n",
    "corr = round(np.corrcoef(x, y)[0,1],2)\n",
    "plt.title('Exam 3 vs. Final Grade;' ' $\\mathit{r}$ = ' + \"{:.2f}\".format(corr))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df5['Study_Hours'] \n",
    "y = df5['Final_Grade']\n",
    "plt.title('Exam 3 vs. Final Grade')\n",
    "plt.xlabel('Study_Hours')       \n",
    "plt.ylabel('Final Grade')           \n",
    "\n",
    "# create best-fit line based on slope-intercept form\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.scatter(x, y) \n",
    "plt.plot(x, m*x+b, color = 'red')\n",
    "corr = round(np.corrcoef(x, y)[0,1],2)\n",
    "plt.title('Study Hours vs. Final Grade;' ' $\\mathit{r}$ = ' + \n",
    "          \"{:.2f}\".format(corr))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplots in a Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = 'Final_Grade'\n",
    "x_columns = ['Exam 1', 'Exam 2', 'Exam 3', 'Study_Hours']\n",
    "\n",
    "for x_col in x_columns:\n",
    "    figure = plt.figure()\n",
    "    ax = plt.gca()\n",
    "    m, b = np.polyfit(df5[x_col], df5[y_col], 1)\n",
    "    plt.plot(df5[x_col], m*df5[x_col]+b, color = 'red')\n",
    "    ax.scatter(df5[x_col], df5[y_col])\n",
    "    ax.set_xlabel(x_col)\n",
    "    ax.set_ylabel(y_col)\n",
    "    corr = round(np.corrcoef(df5[x_col], df5[y_col])[0,1],2) \n",
    "    ax.set_title('{} vs. {};'.format(x_col, y_col) \n",
    "                 + ' $\\mathit{r}$ = ' \n",
    "                 + '{:.2f}'.format(corr))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = b_{0} + b_{1}x_{1} + b_{2}x_{2} + ... + b_{n}x_{n} + \\varepsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Univariate analysis  \n",
    "$y = b_{0} + b_{1}x_{1} + \\varepsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate analysis\n",
    "X1 = df5['Exam 1']\n",
    "y = df5['Final_Grade']\n",
    "\n",
    "import statsmodels.api as sm # use stats models for basic linear regression\n",
    "X1 = sm.add_constant(X1) # adds constant to the model\n",
    "model = sm.OLS(y, X1).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = 32.05 + 0.36 \\text{ (Exam 1)} + \\varepsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For the following exercises, we will work with the `Facebook metrics` dataset $^1$**  \n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Facebook+metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "facebook = pd.read_csv('dataset_Facebook.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's leverage the data to run a linear regression model that predicts the `Total Interactions` (dependent variable ) based on the other columns of data (independent variables $x_1, x_2, x_3, \\cdots x_{n}$).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we cannot have non-encoded categorical features in a linear regression model\n",
    "# since the model only relies on numerical data\n",
    "\n",
    "facebook['Type'].value_counts() # let's inspect the 'Type' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook_enc = pd.get_dummies(facebook, columns = ['Type'])\n",
    "facebook_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook_enc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = pd.DataFrame(facebook_enc.isnull().sum(), columns=['Nulls'])\n",
    "nulls = nulls[nulls['Nulls']>0]\n",
    "nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the missing values with mean since few of them\n",
    "facebook_enc['Paid'].fillna((facebook_enc)['Paid'].mean(), inplace=True)\n",
    "facebook_enc['like'].fillna((facebook_enc)['like'].mean(), inplace=True)\n",
    "facebook_enc['share'].fillna((facebook_enc)['share'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign independent variables, dependent variable, respectively\n",
    "x = facebook_enc.loc[:, facebook_enc.columns != 'Total Interactions']\n",
    "# define the target\n",
    "y = pd.DataFrame(facebook_enc['Total Interactions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(X_train)\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model Coefficients:', sk_model.coef_)\n",
    "print()\n",
    "print('Intercept:', sk_model.intercept_)\n",
    "coef = pd.DataFrame(sk_model.coef_.T, columns=['Coefficients'])\n",
    "cols = pd.DataFrame(x.columns, columns=['Columns'])\n",
    "joined = pd.concat([cols['Columns'], coef['Coefficients']], axis=1)\n",
    "joined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sk_model.predict(x_test)\n",
    "pd.DataFrame(predictions, columns=['Predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, predictions)\n",
    "plt.title('Predictions vs. Actual')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "\n",
    "\n",
    "$^{1}$ Moro, S., Rita, P., & Vala B. (2016). Predicting social media performance metrics and evaluation \n",
    "   of the impact on brand building: A data mining approach. *Journal of Business Research, Elsevier,* 3341â€“3351.  \n",
    "   https://doi.org/10.1016/j.jbusres.2016.02.010\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
